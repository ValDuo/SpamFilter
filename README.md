Модель спроектирована и обучена на основе набора данных спам-фильтра Картика Вееракумера, который находится в общем доступе (https://www.kaggle.com/datasets/karthickveerakumar/spam-filter). 
Применены методы работы с датасетами (PySpark), а также другие изученные инструменты для работы с данными (Sqoop, Kafka, Flume). 
Итогом работы является готовая функционирующая утилита для анализа письма на предмет спама, которую можно будет применить на практике и даже интегрировать в работу других компаний,
которые занимаются систематической отправкой рассылок и писем своим клиентам, дабы помочь им увеличить охваты аудиторий и эффективность работы с письмами.
Датасет был загружен в HDFS и MariaDB, а затем обрабатывался с помощью PySpark. Начальный датасет:
<img width="559" height="489" alt="image" src="https://github.com/user-attachments/assets/b655229e-e1b8-49e0-8f74-27751cdf552a" />
Обработка датасета:
<img width="975" height="547" alt="image" src="https://github.com/user-attachments/assets/de50ff5b-81c8-4971-b472-aa3179b770cd" />
Работа над моделью началась с решения алгоритмом Байеса, где вероятность спама можно вычислить с помощью независимых событий, которыми являются слова в тексте сообщения. 
Чем чаще слово попадается в спаме, тем больше вероятность, что оно и является телом нежелательного сообщения.
<img width="1043" height="607" alt="image" src="https://github.com/user-attachments/assets/92f28297-aa35-425e-990b-b6b2217ce04e" />
<img width="728" height="117" alt="image" src="https://github.com/user-attachments/assets/72431a05-ed5d-4446-bd92-a66af44d9167" />
<img width="508" height="98" alt="image" src="https://github.com/user-attachments/assets/9ea1dffc-2b7f-4f40-ab1c-c9c087f3b23d" />

После завершения работы над самописным кодом Байеса был сделан вывод, что модель далека от совершенства и мы решили прибегнуть к встроенному функционалу библиотеки PySpark.
Нами были созданы и обучены 6 моделей  
<img width="1574" height="537" alt="image" src="https://github.com/user-attachments/assets/1a2cf4ab-75be-43eb-b876-98317b9a978d" />

Самой точной из них оказалась модель логистической регрессии с точностью 0.976
<img width="1217" height="949" alt="image" src="https://github.com/user-attachments/assets/2509ce37-3b2f-42d9-a4b4-0586ce9ef90a" />
С помощью инструмента анализа и визуализации данных был создан и выведен отчет по частоте встречаемости популярных (их кол-во > 30.000) спам-слов, которые содержатся в датасете мощностью 248.000 писем.
<img width="2010" height="62" alt="image" src="https://github.com/user-attachments/assets/c0269dd4-7bf1-441e-a985-a47c21f2d7a8" />

<img width="1336" height="840" alt="image" src="https://github.com/user-attachments/assets/9679e6ee-55c9-409b-8252-2ed94452ecb3" />

На ее основе был создан сайт и API. Сайт написан на Python/Django с использованием HTML/CSS/JS. На сайте можно проверить, является ли сообщение спамом. Кроме того, ресурс предоставляет API для разработчиков, чтобы делать аналогичные запросы по http. 
API задокументировано с помощью swagger. 
<img width="553" height="737" alt="image" src="https://github.com/user-attachments/assets/2909138f-d5ae-4062-84f0-3f248a15390d" />
<img width="1160" height="556" alt="image" src="https://github.com/user-attachments/assets/850cf0b3-f8aa-4b0a-8b08-34c660b314db" />

Для ускорения работы сервера используется NoSQL база данных redis, которая работает по схеме ключ:значение. Если сообщение уже посылалось на сервер, то результат работы извлекается из кеша, что экономит время и вычислительные мощности.

